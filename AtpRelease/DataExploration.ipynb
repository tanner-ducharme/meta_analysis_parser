{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: do a binary log reg using the statistics gathered above. \n",
    "# Maybe do an ensemble method, using the predicted probability from a naive bayes as a feature?\n",
    "# look into de-duplication\n",
    "\n",
    "# find which terms return no results, remove\n",
    "# then check which papers mention any of atp words OR any of stimulation words (grouped together)\n",
    "# do a quick scatter plot visualizing atp mentions vs mechanical word mentions\n",
    "# ADD SINGLE TERMS TO QUERY LIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into stanford core nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanner\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import operator\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_pickle(\"data/data_frame_no_paper.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/atprelease_query_terms1.pkl', 'rb') as f:\n",
    "    query_terms1 = pickle.load(f)\n",
    "    \n",
    "with open('data/atprelease_query_terms2.pkl', 'rb') as f:\n",
    "    query_terms2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_dict_by_values(dictionary, min_freq):\n",
    "    sorted_list = [(k, dictionary[k]) for k in sorted(dictionary, key=dictionary.get, reverse=True)]\n",
    "    \n",
    "    \n",
    "    sorted_dict = {}\n",
    "    for e in sorted_list[:1000]:\n",
    "        if e[1] >= min_freq:\n",
    "            sorted_dict[e[0]] = e[1]\n",
    "    \n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(normalizer, dictionary):\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        if np.around(dictionary[key]/normalizer, 3) > 0:\n",
    "            new_dict[key] = np.around(dictionary[key]/normalizer, 3)\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_relevant(df):\n",
    "    counts = df['relevant'].value_counts()\n",
    "    relevant = counts[1]\n",
    "    irrelevant  = counts[0]\n",
    "    return relevant, irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get various tallies of all words\n",
    "\n",
    "title_tally_R    = {}\n",
    "keyword_tally_R  = {}\n",
    "abstract_tally_R = {}\n",
    "corpus_tally_R   = {}\n",
    "\n",
    "title_tally_NR    = {}\n",
    "keyword_tally_NR  = {}\n",
    "abstract_tally_NR = {}\n",
    "corpus_tally_NR   = {}\n",
    "\n",
    "for row in text_df.iterrows():\n",
    "    row = row[1]\n",
    "    \n",
    "    relevant        = row.relevant\n",
    "    title_corpus    = row.title_corpus\n",
    "    keyword_corpus  = row.keyword_corpus\n",
    "    abstract_corpus = row.abstract_corpus\n",
    "    total_corpus    = row.all_text_corpus\n",
    "    \n",
    "        \n",
    "    if relevant:\n",
    "        \n",
    "        for word in title_corpus:            \n",
    "            if word in title_tally_R:\n",
    "                title_tally_R[word] += 1                \n",
    "            else:\n",
    "                title_tally_R[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_R:\n",
    "                corpus_tally_R[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_R[word]  = 1                \n",
    "        \n",
    "        for word in keyword_corpus:            \n",
    "            if word in keyword_tally_R:\n",
    "                keyword_tally_R[word] += 1                \n",
    "            else:\n",
    "                keyword_tally_R[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_R:\n",
    "                corpus_tally_R[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_R[word]  = 1\n",
    "        \n",
    "        for word in abstract_corpus:            \n",
    "            if word in abstract_tally_R:\n",
    "                abstract_tally_R[word] += 1                \n",
    "            else:\n",
    "                abstract_tally_R[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_R:\n",
    "                corpus_tally_R[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_R[word]  = 1\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        for word in title_corpus:            \n",
    "            if word in title_tally_NR:\n",
    "                title_tally_NR[word] += 1                \n",
    "            else:\n",
    "                title_tally_NR[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_NR:\n",
    "                corpus_tally_NR[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_NR[word]  = 1                \n",
    "        \n",
    "        for word in keyword_corpus:            \n",
    "            if word in keyword_tally_NR:\n",
    "                keyword_tally_NR[word] += 1                \n",
    "            else:\n",
    "                keyword_tally_NR[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_NR:\n",
    "                corpus_tally_NR[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_NR[word]  = 1\n",
    "        \n",
    "        for word in abstract_corpus:            \n",
    "            if word in abstract_tally_NR:\n",
    "                abstract_tally_NR[word] += 1                \n",
    "            else:\n",
    "                abstract_tally_NR[word]  = 1\n",
    "            \n",
    "            if word in corpus_tally_NR:\n",
    "                corpus_tally_NR[word] += 1                \n",
    "            else:\n",
    "                corpus_tally_NR[word]  = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tally_R      = sort_dict_by_values(title_tally_R, 1)\n",
    "keyword_tally_R    = sort_dict_by_values(keyword_tally_R, 1)\n",
    "abstract_tally_R   = sort_dict_by_values(abstract_tally_R, 1)\n",
    "corpus_tally_R     = sort_dict_by_values(corpus_tally_R, 1)\n",
    "\n",
    "title_tally_NR     = sort_dict_by_values(title_tally_NR, 1)\n",
    "keyword_tally_NR   = sort_dict_by_values(keyword_tally_NR, 1)\n",
    "abstract_tally_NR  = sort_dict_by_values(abstract_tally_NR, 1)\n",
    "corpus_tally_NR    = sort_dict_by_values(corpus_tally_NR, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qt_title_tally_R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-61e9524795da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery_terms1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrelevant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt_title_tally_R\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                     \u001b[0mqt_title_tally_R\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qt_title_tally_R' is not defined"
     ]
    }
   ],
   "source": [
    "# get various tallies of all query terms\n",
    "\n",
    "qt1_title_tally_R    = {}\n",
    "qt1_keyword_tally_R  = {}\n",
    "qt1_abstract_tally_R = {}\n",
    "qt1_corpus_tally_R   = {}\n",
    "\n",
    "qt1_title_tally_NR    = {}\n",
    "qt1_keyword_tally_NR  = {}\n",
    "qt1_abstract_tally_NR = {}\n",
    "qt1_corpus_tally_NR   = {}\n",
    "\n",
    "for row in text_df.iterrows():\n",
    "    row = row[1]\n",
    "    relevant        = row.relevant\n",
    "    title_corpus    = row.title_corpus\n",
    "    keyword_corpus  = row.keyword_corpus\n",
    "    abstract_corpus = row.abstract_corpus\n",
    "    total_corpus    = row.all_text_corpus        \n",
    "\n",
    "        \n",
    "    for word in title_corpus:\n",
    "\n",
    "        if word in query_terms1:\n",
    "            if relevant:\n",
    "                if word in qt_title_tally_R:\n",
    "                    qt_title_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_title_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1      \n",
    "            else:\n",
    "                if word in qt_title_tally_NR:\n",
    "                    qt_title_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_title_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1   \n",
    "\n",
    "    for word in keyword_corpus:  \n",
    "\n",
    "        if word in query_terms1:\n",
    "            if relevant:\n",
    "                if word in qt_keyword_tally_R:\n",
    "                    qt_keyword_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_keyword_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1\n",
    "            else:\n",
    "                if word in qt_keyword_tally_NR:\n",
    "                    qt_keyword_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_keyword_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1\n",
    "\n",
    "\n",
    "    for word in abstract_corpus:  \n",
    "\n",
    "        if word in query_terms1:\n",
    "            if relevant:\n",
    "                if word in qt_abstract_tally_R:\n",
    "                    qt_abstract_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_abstract_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1\n",
    "            else:\n",
    "\n",
    "                if word in qt_abstract_tally_NR:\n",
    "                    qt_abstract_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_abstract_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qt_title_tally_R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aaef545ac9fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery_terms2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrelevant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt_title_tally_R\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                     \u001b[0mqt_title_tally_R\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qt_title_tally_R' is not defined"
     ]
    }
   ],
   "source": [
    "# get various tallies of all query terms\n",
    "\n",
    "qt2_title_tally_R    = {}\n",
    "qt2_keyword_tally_R  = {}\n",
    "qt2_abstract_tally_R = {}\n",
    "qt2_corpus_tally_R   = {}\n",
    "\n",
    "qt2_title_tally_NR    = {}\n",
    "qt2_keyword_tally_NR  = {}\n",
    "qt2_abstract_tally_NR = {}\n",
    "qt2_corpus_tally_NR   = {}\n",
    "\n",
    "for row in text_df.iterrows():\n",
    "    row = row[1]\n",
    "    relevant        = row.relevant\n",
    "    title_corpus    = row.title_corpus\n",
    "    keyword_corpus  = row.keyword_corpus\n",
    "    abstract_corpus = row.abstract_corpus\n",
    "    total_corpus    = row.all_text_corpus        \n",
    "\n",
    "        \n",
    "    for word in title_corpus:\n",
    "\n",
    "        if word in query_terms2:\n",
    "            if relevant:\n",
    "                if word in qt_title_tally_R:\n",
    "                    qt_title_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_title_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1      \n",
    "            else:\n",
    "                if word in qt_title_tally_NR:\n",
    "                    qt_title_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_title_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1   \n",
    "\n",
    "    for word in keyword_corpus:  \n",
    "\n",
    "        if word in query_terms2:\n",
    "            if relevant:\n",
    "                if word in qt_keyword_tally_R:\n",
    "                    qt_keyword_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_keyword_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1\n",
    "            else:\n",
    "                if word in qt_keyword_tally_NR:\n",
    "                    qt_keyword_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_keyword_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1\n",
    "\n",
    "\n",
    "    for word in abstract_corpus:  \n",
    "\n",
    "        if word in query_terms2:\n",
    "            if relevant:\n",
    "                if word in qt_abstract_tally_R:\n",
    "                    qt_abstract_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_abstract_tally_R[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_R:\n",
    "                    qt_corpus_tally_R[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_R[word]  = 1\n",
    "            else:\n",
    "\n",
    "                if word in qt_abstract_tally_NR:\n",
    "                    qt_abstract_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_abstract_tally_NR[word]  = 1\n",
    "\n",
    "                if word in qt_corpus_tally_NR:\n",
    "                    qt_corpus_tally_NR[word] += 1                \n",
    "                else:\n",
    "                    qt_corpus_tally_NR[word]  = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt1_title_tally_R      = sort_dict_by_values(qt1_title_tally_R, 2)\n",
    "qt1_keyword_tally_R    = sort_dict_by_values(qt1_keyword_tally_R, 2)\n",
    "qt1_abstract_tally_R   = sort_dict_by_values(qt1_abstract_tally_R, 2)\n",
    "qt1_corpus_tally_R     = sort_dict_by_values(qt1_corpus_tally_R, 2)\n",
    "\n",
    "qt1_title_tally_NR     = sort_dict_by_values(qt1_title_tally_NR, 2)\n",
    "qt1_keyword_tally_NR   = sort_dict_by_values(qt1_keyword_tally_NR, 2)\n",
    "qt1_abstract_tally_NR  = sort_dict_by_values(qt1_abstract_tally_NR, 2)\n",
    "qt1_corpus_tally_NR    = sort_dict_by_values(qt1_corpus_tally_NR, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt2_title_tally_R      = sort_dict_by_values(qt2_title_tally_R, 2)\n",
    "qt2_keyword_tally_R    = sort_dict_by_values(qt2_keyword_tally_R, 2)\n",
    "qt2_abstract_tally_R   = sort_dict_by_values(qt2_abstract_tally_R, 2)\n",
    "qt2_corpus_tally_R     = sort_dict_by_values(qt2_corpus_tally_R, 2)\n",
    "\n",
    "qt2_title_tally_NR     = sort_dict_by_values(qt2_title_tally_NR, 2)\n",
    "qt2_keyword_tally_NR   = sort_dict_by_values(qt2_keyword_tally_NR, 2)\n",
    "qt2_abstract_tally_NR  = sort_dict_by_values(qt2_abstract_tally_NR, 2)\n",
    "qt2_corpus_tally_NR    = sort_dict_by_values(qt2_corpus_tally_NR, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_paper_per_keyword(terms, df):\n",
    "    qt_count    = {}  # tally of how many papers each keyword appear in \n",
    "\n",
    "    qt_count_R  = {}  # tally of how many relevant papers each keyword appear in\n",
    "\n",
    "    qt_count_NR = {}  # tally of how many not relevant papers each keyword appear in\n",
    "\n",
    "    for term in terms:\n",
    "        qt_count[term]         = 0\n",
    "        qt_count_R[term]       = 0\n",
    "        qt_count_NR[term]      = 0\n",
    "\n",
    "    for term in terms:\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            if term in row.all_text_corpus:\n",
    "                if row.relevant==True:               \n",
    "                    qt_count_R[term] +=1\n",
    "                else:\n",
    "                    qt_count_NR[term] +=1\n",
    "\n",
    "                qt_count[term] +=1\n",
    "    \n",
    "    return sort_dict_by_values(qt_count, 1).copy(), sort_dict_by_values(qt_count_R, 1).copy(), sort_dict_by_values(qt_count_NR, 1).copy()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt1_count, qt1_count_R, qt1_count_NR = num_paper_per_keyword(query_terms1, text_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt2_count, qt2_count_R, qt2_count_NR = num_paper_per_keyword(query_terms2, text_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/query_term_count.pkl', 'wb') as handle:\n",
    "    pickle.dump(qt2_count, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('data/query_term_count_relevant.pkl', 'wb') as handle:\n",
    "    pickle.dump(qt2_count_R, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('data/query_term_count_irrelevant.pkl', 'wb') as handle:\n",
    "    pickle.dump(qt2_count_NR, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atp': 0.989,\n",
       " 'adenosine triphosphate': 0.874,\n",
       " 'mechan stimul': 0.152,\n",
       " 'mechan stress': 0.076,\n",
       " 'mechan stretch': 0.065,\n",
       " 'hypoton stress': 0.065,\n",
       " 'mechan load': 0.054,\n",
       " 'mechan deform': 0.051,\n",
       " 'mechan strain': 0.04,\n",
       " 'hydrostat pressur': 0.036,\n",
       " 'mechan forc': 0.036,\n",
       " 'hypoton shock': 0.029,\n",
       " 'hypoton exposur': 0.022,\n",
       " 'mechan perturb': 0.018,\n",
       " 'membran stretch': 0.014,\n",
       " 'hypoton stimul': 0.014,\n",
       " 'hypoton swell': 0.011,\n",
       " 'mechan pressur': 0.007,\n",
       " 'mechan transduc': 0.004,\n",
       " 'membran stress': 0.004,\n",
       " 'hypoton stretch': 0.004,\n",
       " 'osmotic stress': 0.004}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(get_num_relevant(text_df)[0], qt1_count_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qt2_count_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atp': 0.989,\n",
       " 'adenosine triphosphate': 0.874,\n",
       " 'mechan': 0.726,\n",
       " 'stimul': 0.534,\n",
       " 'stress': 0.339,\n",
       " 'membran': 0.249,\n",
       " 'hypoton': 0.245,\n",
       " 'stretch': 0.152,\n",
       " 'mechan stimul': 0.152,\n",
       " 'pressur': 0.148,\n",
       " 'exposur': 0.137,\n",
       " 'load': 0.116,\n",
       " 'swell': 0.105,\n",
       " 'mechan stress': 0.076,\n",
       " 'forc': 0.072,\n",
       " 'deform': 0.069,\n",
       " 'strain': 0.065,\n",
       " 'mechan stretch': 0.065,\n",
       " 'hypoton stress': 0.065,\n",
       " 'shock': 0.054,\n",
       " 'mechan load': 0.054,\n",
       " 'mechan deform': 0.051,\n",
       " 'mechan strain': 0.04,\n",
       " 'hydrostat': 0.036,\n",
       " 'hydrostat pressur': 0.036,\n",
       " 'mechan forc': 0.036,\n",
       " 'compress': 0.036,\n",
       " 'perturb': 0.029,\n",
       " 'hypoton shock': 0.029,\n",
       " 'hypoton exposur': 0.022,\n",
       " 'transduc': 0.018,\n",
       " 'mechan perturb': 0.018,\n",
       " 'membran stretch': 0.014,\n",
       " 'hypoton stimul': 0.014,\n",
       " 'hypoton swell': 0.011,\n",
       " 'displac': 0.011,\n",
       " 'centrifug': 0.011,\n",
       " 'mechan pressur': 0.007,\n",
       " 'mechan transduc': 0.004,\n",
       " 'membran stress': 0.004,\n",
       " 'shrink': 0.004,\n",
       " 'vibrat': 0.004,\n",
       " 'hypoton stretch': 0.004,\n",
       " 'osmotic stress': 0.004}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(get_num_relevant(text_df)[0], qt2_count_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_keywords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9fa804376fb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt1_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnum_keywords\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt1_count_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_keywords' is not defined"
     ]
    }
   ],
   "source": [
    "num_keywords1 = 0 # percentage of keywords that appear in any of the paper text\n",
    "num_keywords_R1 = 0 # percentage of keywords that appear in relevent of the paper text\n",
    "num_keywords_NR1 = 0 # percentage of keywords that appear in not relevent of the paper text\n",
    "\n",
    "for key, value in qt1_count.items():\n",
    "    if value > 0:\n",
    "        num_keywords += 1\n",
    "        \n",
    "for key, value in qt1_count_R.items():\n",
    "    if value > 0:\n",
    "        num_keywords_R += 1\n",
    "        \n",
    "for key, value in qt1_count_NR.items():\n",
    "    if value > 0:\n",
    "        num_keywords_NR += 1\n",
    "        \n",
    "percent_kw = num_keywords / len(query_terms1)\n",
    "percent_kw_R = num_keywords_R / len(query_terms1)\n",
    "percent_kw_NR = num_keywords_NR / len(query_terms1)\n",
    "\n",
    "print('percentage of keywords that appear in all papers:          {}'.format(percent_kw))\n",
    "print('percentage of keywords that appear in relevant papers:     {}'.format(percent_kw_R))\n",
    "print('percentage of keywords that appear in not relevant papers: {}'.format(percent_kw_NR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_keywords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c99c9066e22d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt2_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnum_keywords\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqt2_count_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_keywords' is not defined"
     ]
    }
   ],
   "source": [
    "num_keywords2 = 0 # percentage of keywords that appear in any of the paper text\n",
    "num_keywords_R2 = 0 # percentage of keywords that appear in relevent of the paper text\n",
    "num_keywords_NR2 = 0 # percentage of keywords that appear in not relevent of the paper text\n",
    "\n",
    "for key, value in qt2_count.items():\n",
    "    if value > 0:\n",
    "        num_keywords += 1\n",
    "        \n",
    "for key, value in qt2_count_R.items():\n",
    "    if value > 0:\n",
    "        num_keywords_R += 1\n",
    "        \n",
    "for key, value in qt2_count_NR.items():\n",
    "    if value > 0:\n",
    "        num_keywords_NR += 1\n",
    "        \n",
    "percent_kw2 = num_keywords / len(query_terms2)\n",
    "percent_kw_R2 = num_keywords_R / len(query_terms2)\n",
    "percent_kw_NR2 = num_keywords_NR / len(query_terms2)\n",
    "\n",
    "print('percentage of keywords2 that appear in the papers:          {}'.format(percent_kw2))\n",
    "print('percentage of keywords2 that appear in relevant papers:     {}'.format(percent_kw_R2))\n",
    "print('percentage of keywords2 that appear in not relevant papers: {}'.format(percent_kw_NR2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore above cell more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qt_count         = sort_dict_by_values(qt_count, 0)\n",
    "# # qt_freq_count    = sort_dict_by_values(qt_freq_count, 0)\n",
    "\n",
    "# qt_count_R       = sort_dict_by_values(qt_count_R, 0)\n",
    "# # qt_freq_count_R  = sort_dict_by_values(qt_freq_count_R, 0)\n",
    "\n",
    "# qt_count_NR      = sort_dict_by_values(qt_count_NR, 0)\n",
    "# # qt_freq_count_NR = sort_dict_by_values(qt_freq_count_NR, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we'll determine which words appear in which class at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1/200 terms\n",
      "processed 2/200 terms\n",
      "processed 3/200 terms\n",
      "processed 4/200 terms\n",
      "processed 5/200 terms\n",
      "processed 6/200 terms\n",
      "processed 7/200 terms\n",
      "processed 8/200 terms\n",
      "processed 9/200 terms\n",
      "processed 10/200 terms\n",
      "processed 11/200 terms\n",
      "processed 12/200 terms\n",
      "processed 13/200 terms\n",
      "processed 14/200 terms\n",
      "processed 15/200 terms\n",
      "processed 16/200 terms\n",
      "processed 17/200 terms\n",
      "processed 18/200 terms\n",
      "processed 19/200 terms\n",
      "processed 20/200 terms\n",
      "processed 21/200 terms\n",
      "processed 22/200 terms\n",
      "processed 23/200 terms\n",
      "processed 24/200 terms\n",
      "processed 25/200 terms\n",
      "processed 26/200 terms\n",
      "processed 27/200 terms\n",
      "processed 28/200 terms\n",
      "processed 29/200 terms\n",
      "processed 30/200 terms\n",
      "processed 31/200 terms\n",
      "processed 32/200 terms\n",
      "processed 33/200 terms\n",
      "processed 34/200 terms\n",
      "processed 35/200 terms\n",
      "processed 36/200 terms\n",
      "processed 37/200 terms\n",
      "processed 38/200 terms\n",
      "processed 39/200 terms\n",
      "processed 40/200 terms\n",
      "processed 41/200 terms\n",
      "processed 42/200 terms\n",
      "processed 43/200 terms\n",
      "processed 44/200 terms\n",
      "processed 45/200 terms\n",
      "processed 46/200 terms\n",
      "processed 47/200 terms\n",
      "processed 48/200 terms\n",
      "processed 49/200 terms\n",
      "processed 50/200 terms\n",
      "processed 51/200 terms\n",
      "processed 52/200 terms\n",
      "processed 53/200 terms\n",
      "processed 54/200 terms\n",
      "processed 55/200 terms\n",
      "processed 56/200 terms\n",
      "processed 57/200 terms\n",
      "processed 58/200 terms\n",
      "processed 59/200 terms\n",
      "processed 60/200 terms\n",
      "processed 61/200 terms\n",
      "processed 62/200 terms\n",
      "processed 63/200 terms\n",
      "processed 64/200 terms\n",
      "processed 65/200 terms\n",
      "processed 66/200 terms\n",
      "processed 67/200 terms\n",
      "processed 68/200 terms\n",
      "processed 69/200 terms\n",
      "processed 70/200 terms\n",
      "processed 71/200 terms\n",
      "processed 72/200 terms\n",
      "processed 73/200 terms\n",
      "processed 74/200 terms\n",
      "processed 75/200 terms\n",
      "processed 76/200 terms\n",
      "processed 77/200 terms\n",
      "processed 78/200 terms\n",
      "processed 79/200 terms\n",
      "processed 80/200 terms\n",
      "processed 81/200 terms\n",
      "processed 82/200 terms\n",
      "processed 83/200 terms\n",
      "processed 84/200 terms\n",
      "processed 85/200 terms\n",
      "processed 86/200 terms\n",
      "processed 87/200 terms\n",
      "processed 88/200 terms\n",
      "processed 89/200 terms\n",
      "processed 90/200 terms\n",
      "processed 91/200 terms\n",
      "processed 92/200 terms\n",
      "processed 93/200 terms\n",
      "processed 94/200 terms\n",
      "processed 95/200 terms\n",
      "processed 96/200 terms\n",
      "processed 97/200 terms\n",
      "processed 98/200 terms\n",
      "processed 99/200 terms\n",
      "processed 100/200 terms\n",
      "processed 101/200 terms\n",
      "processed 102/200 terms\n",
      "processed 103/200 terms\n",
      "processed 104/200 terms\n",
      "processed 105/200 terms\n",
      "processed 106/200 terms\n",
      "processed 107/200 terms\n",
      "processed 108/200 terms\n",
      "processed 109/200 terms\n",
      "processed 110/200 terms\n",
      "processed 111/200 terms\n",
      "processed 112/200 terms\n",
      "processed 113/200 terms\n",
      "processed 114/200 terms\n",
      "processed 115/200 terms\n",
      "processed 116/200 terms\n",
      "processed 117/200 terms\n",
      "processed 118/200 terms\n",
      "processed 119/200 terms\n",
      "processed 120/200 terms\n",
      "processed 121/200 terms\n",
      "processed 122/200 terms\n",
      "processed 123/200 terms\n",
      "processed 124/200 terms\n",
      "processed 125/200 terms\n",
      "processed 126/200 terms\n",
      "processed 127/200 terms\n",
      "processed 128/200 terms\n",
      "processed 129/200 terms\n",
      "processed 130/200 terms\n",
      "processed 131/200 terms\n",
      "processed 132/200 terms\n",
      "processed 133/200 terms\n",
      "processed 134/200 terms\n",
      "processed 135/200 terms\n",
      "processed 136/200 terms\n",
      "processed 137/200 terms\n",
      "processed 138/200 terms\n",
      "processed 139/200 terms\n",
      "processed 140/200 terms\n",
      "processed 141/200 terms\n",
      "processed 142/200 terms\n",
      "processed 143/200 terms\n",
      "processed 144/200 terms\n",
      "processed 145/200 terms\n",
      "processed 146/200 terms\n",
      "processed 147/200 terms\n",
      "processed 148/200 terms\n",
      "processed 149/200 terms\n",
      "processed 150/200 terms\n",
      "processed 151/200 terms\n",
      "processed 152/200 terms\n",
      "processed 153/200 terms\n",
      "processed 154/200 terms\n",
      "processed 155/200 terms\n",
      "processed 156/200 terms\n",
      "processed 157/200 terms\n",
      "processed 158/200 terms\n",
      "processed 159/200 terms\n",
      "processed 160/200 terms\n",
      "processed 161/200 terms\n",
      "processed 162/200 terms\n",
      "processed 163/200 terms\n",
      "processed 164/200 terms\n",
      "processed 165/200 terms\n",
      "processed 166/200 terms\n",
      "processed 167/200 terms\n",
      "processed 168/200 terms\n",
      "processed 169/200 terms\n",
      "processed 170/200 terms\n",
      "processed 171/200 terms\n",
      "processed 172/200 terms\n",
      "processed 173/200 terms\n",
      "processed 174/200 terms\n",
      "processed 175/200 terms\n",
      "processed 176/200 terms\n",
      "processed 177/200 terms\n",
      "processed 178/200 terms\n",
      "processed 179/200 terms\n",
      "processed 180/200 terms\n",
      "processed 181/200 terms\n",
      "processed 182/200 terms\n",
      "processed 183/200 terms\n",
      "processed 184/200 terms\n",
      "processed 185/200 terms\n",
      "processed 186/200 terms\n",
      "processed 187/200 terms\n",
      "processed 188/200 terms\n",
      "processed 189/200 terms\n",
      "processed 190/200 terms\n",
      "processed 191/200 terms\n",
      "processed 192/200 terms\n",
      "processed 193/200 terms\n",
      "processed 194/200 terms\n",
      "processed 195/200 terms\n",
      "processed 196/200 terms\n",
      "processed 197/200 terms\n",
      "processed 198/200 terms\n",
      "processed 199/200 terms\n",
      "processed 200/200 terms\n"
     ]
    }
   ],
   "source": [
    "both1       = []\n",
    "none1       = []\n",
    "R_not_NR1   = []\n",
    "NR_not_R1   = []\n",
    "ctr = 1\n",
    "for term in query_terms1:\n",
    "    \n",
    "    \n",
    "    in_relevant = False\n",
    "    in_not_relevant = False\n",
    "    # if term appears in just once paper we mark it true\n",
    "    for index, row in text_df.iterrows():        \n",
    "        \n",
    "        if term in row.all_text_corpus:\n",
    "            \n",
    "            if row.relevant == True:\n",
    "                in_relevant = True\n",
    "                \n",
    "            else:\n",
    "                in_not_relevant = True\n",
    "                \n",
    "    \n",
    "    if in_relevant == True and in_not_relevant == True: # word appears in both classes at least once\n",
    "        both1.append(term)\n",
    "        \n",
    "    elif in_relevant == False and in_not_relevant == False: # word never appears in either class\n",
    "        none1.append(term)\n",
    "    \n",
    "    elif in_relevant == False and in_not_relevant == True: # word appears in non relevant papers at least once but never in relevant papers\n",
    "        NR_not_R1.append(term)\n",
    "        \n",
    "    else:                    # word appears in relevant papers at least once but never in non relevant papers\n",
    "        R_not_NR1.append(term)   \n",
    "    \n",
    "    print(\"processed {}/{} terms\".format(ctr, len(query_terms1)))\n",
    "    ctr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1/230 terms\n",
      "processed 2/230 terms\n",
      "processed 3/230 terms\n",
      "processed 4/230 terms\n",
      "processed 5/230 terms\n",
      "processed 6/230 terms\n",
      "processed 7/230 terms\n",
      "processed 8/230 terms\n",
      "processed 9/230 terms\n",
      "processed 10/230 terms\n",
      "processed 11/230 terms\n",
      "processed 12/230 terms\n",
      "processed 13/230 terms\n",
      "processed 14/230 terms\n",
      "processed 15/230 terms\n",
      "processed 16/230 terms\n",
      "processed 17/230 terms\n",
      "processed 18/230 terms\n",
      "processed 19/230 terms\n",
      "processed 20/230 terms\n",
      "processed 21/230 terms\n",
      "processed 22/230 terms\n",
      "processed 23/230 terms\n",
      "processed 24/230 terms\n",
      "processed 25/230 terms\n",
      "processed 26/230 terms\n",
      "processed 27/230 terms\n",
      "processed 28/230 terms\n",
      "processed 29/230 terms\n",
      "processed 30/230 terms\n",
      "processed 31/230 terms\n",
      "processed 32/230 terms\n",
      "processed 33/230 terms\n",
      "processed 34/230 terms\n",
      "processed 35/230 terms\n",
      "processed 36/230 terms\n",
      "processed 37/230 terms\n",
      "processed 38/230 terms\n",
      "processed 39/230 terms\n",
      "processed 40/230 terms\n",
      "processed 41/230 terms\n",
      "processed 42/230 terms\n",
      "processed 43/230 terms\n",
      "processed 44/230 terms\n",
      "processed 45/230 terms\n",
      "processed 46/230 terms\n",
      "processed 47/230 terms\n",
      "processed 48/230 terms\n",
      "processed 49/230 terms\n",
      "processed 50/230 terms\n",
      "processed 51/230 terms\n",
      "processed 52/230 terms\n",
      "processed 53/230 terms\n",
      "processed 54/230 terms\n",
      "processed 55/230 terms\n",
      "processed 56/230 terms\n",
      "processed 57/230 terms\n",
      "processed 58/230 terms\n",
      "processed 59/230 terms\n",
      "processed 60/230 terms\n",
      "processed 61/230 terms\n",
      "processed 62/230 terms\n",
      "processed 63/230 terms\n",
      "processed 64/230 terms\n",
      "processed 65/230 terms\n",
      "processed 66/230 terms\n",
      "processed 67/230 terms\n",
      "processed 68/230 terms\n",
      "processed 69/230 terms\n",
      "processed 70/230 terms\n",
      "processed 71/230 terms\n",
      "processed 72/230 terms\n",
      "processed 73/230 terms\n",
      "processed 74/230 terms\n",
      "processed 75/230 terms\n",
      "processed 76/230 terms\n",
      "processed 77/230 terms\n",
      "processed 78/230 terms\n",
      "processed 79/230 terms\n",
      "processed 80/230 terms\n",
      "processed 81/230 terms\n",
      "processed 82/230 terms\n",
      "processed 83/230 terms\n",
      "processed 84/230 terms\n",
      "processed 85/230 terms\n",
      "processed 86/230 terms\n",
      "processed 87/230 terms\n",
      "processed 88/230 terms\n",
      "processed 89/230 terms\n",
      "processed 90/230 terms\n",
      "processed 91/230 terms\n",
      "processed 92/230 terms\n",
      "processed 93/230 terms\n",
      "processed 94/230 terms\n",
      "processed 95/230 terms\n",
      "processed 96/230 terms\n",
      "processed 97/230 terms\n",
      "processed 98/230 terms\n",
      "processed 99/230 terms\n",
      "processed 100/230 terms\n",
      "processed 101/230 terms\n",
      "processed 102/230 terms\n",
      "processed 103/230 terms\n",
      "processed 104/230 terms\n",
      "processed 105/230 terms\n",
      "processed 106/230 terms\n",
      "processed 107/230 terms\n",
      "processed 108/230 terms\n",
      "processed 109/230 terms\n",
      "processed 110/230 terms\n",
      "processed 111/230 terms\n",
      "processed 112/230 terms\n",
      "processed 113/230 terms\n",
      "processed 114/230 terms\n",
      "processed 115/230 terms\n",
      "processed 116/230 terms\n",
      "processed 117/230 terms\n",
      "processed 118/230 terms\n",
      "processed 119/230 terms\n",
      "processed 120/230 terms\n",
      "processed 121/230 terms\n",
      "processed 122/230 terms\n",
      "processed 123/230 terms\n",
      "processed 124/230 terms\n",
      "processed 125/230 terms\n",
      "processed 126/230 terms\n",
      "processed 127/230 terms\n",
      "processed 128/230 terms\n",
      "processed 129/230 terms\n",
      "processed 130/230 terms\n",
      "processed 131/230 terms\n",
      "processed 132/230 terms\n",
      "processed 133/230 terms\n",
      "processed 134/230 terms\n",
      "processed 135/230 terms\n",
      "processed 136/230 terms\n",
      "processed 137/230 terms\n",
      "processed 138/230 terms\n",
      "processed 139/230 terms\n",
      "processed 140/230 terms\n",
      "processed 141/230 terms\n",
      "processed 142/230 terms\n",
      "processed 143/230 terms\n",
      "processed 144/230 terms\n",
      "processed 145/230 terms\n",
      "processed 146/230 terms\n",
      "processed 147/230 terms\n",
      "processed 148/230 terms\n",
      "processed 149/230 terms\n",
      "processed 150/230 terms\n",
      "processed 151/230 terms\n",
      "processed 152/230 terms\n",
      "processed 153/230 terms\n",
      "processed 154/230 terms\n",
      "processed 155/230 terms\n",
      "processed 156/230 terms\n",
      "processed 157/230 terms\n",
      "processed 158/230 terms\n",
      "processed 159/230 terms\n",
      "processed 160/230 terms\n",
      "processed 161/230 terms\n",
      "processed 162/230 terms\n",
      "processed 163/230 terms\n",
      "processed 164/230 terms\n",
      "processed 165/230 terms\n",
      "processed 166/230 terms\n",
      "processed 167/230 terms\n",
      "processed 168/230 terms\n",
      "processed 169/230 terms\n",
      "processed 170/230 terms\n",
      "processed 171/230 terms\n",
      "processed 172/230 terms\n",
      "processed 173/230 terms\n",
      "processed 174/230 terms\n",
      "processed 175/230 terms\n",
      "processed 176/230 terms\n",
      "processed 177/230 terms\n",
      "processed 178/230 terms\n",
      "processed 179/230 terms\n",
      "processed 180/230 terms\n",
      "processed 181/230 terms\n",
      "processed 182/230 terms\n",
      "processed 183/230 terms\n",
      "processed 184/230 terms\n",
      "processed 185/230 terms\n",
      "processed 186/230 terms\n",
      "processed 187/230 terms\n",
      "processed 188/230 terms\n",
      "processed 189/230 terms\n",
      "processed 190/230 terms\n",
      "processed 191/230 terms\n",
      "processed 192/230 terms\n",
      "processed 193/230 terms\n",
      "processed 194/230 terms\n",
      "processed 195/230 terms\n",
      "processed 196/230 terms\n",
      "processed 197/230 terms\n",
      "processed 198/230 terms\n",
      "processed 199/230 terms\n",
      "processed 200/230 terms\n",
      "processed 201/230 terms\n",
      "processed 202/230 terms\n",
      "processed 203/230 terms\n",
      "processed 204/230 terms\n",
      "processed 205/230 terms\n",
      "processed 206/230 terms\n",
      "processed 207/230 terms\n",
      "processed 208/230 terms\n",
      "processed 209/230 terms\n",
      "processed 210/230 terms\n",
      "processed 211/230 terms\n",
      "processed 212/230 terms\n",
      "processed 213/230 terms\n",
      "processed 214/230 terms\n",
      "processed 215/230 terms\n",
      "processed 216/230 terms\n",
      "processed 217/230 terms\n",
      "processed 218/230 terms\n",
      "processed 219/230 terms\n",
      "processed 220/230 terms\n",
      "processed 221/230 terms\n",
      "processed 222/230 terms\n",
      "processed 223/230 terms\n",
      "processed 224/230 terms\n",
      "processed 225/230 terms\n",
      "processed 226/230 terms\n",
      "processed 227/230 terms\n",
      "processed 228/230 terms\n",
      "processed 229/230 terms\n",
      "processed 230/230 terms\n"
     ]
    }
   ],
   "source": [
    "both2       = []\n",
    "none2       = []\n",
    "R_not_NR2   = []\n",
    "NR_not_R2   = []\n",
    "ctr = 1\n",
    "for term in query_terms2:\n",
    "    \n",
    "    \n",
    "    in_relevant = False\n",
    "    in_not_relevant = False\n",
    "    # if term appears in just once paper we mark it true\n",
    "    for index, row in text_df.iterrows():        \n",
    "        \n",
    "        if term in row.all_text_corpus:\n",
    "            \n",
    "            if row.relevant == True:\n",
    "                in_relevant = True\n",
    "                \n",
    "            else:\n",
    "                in_not_relevant = True\n",
    "                \n",
    "    \n",
    "    if in_relevant == True and in_not_relevant == True: # word appears in both classes at least once\n",
    "        both2.append(term)\n",
    "        \n",
    "    elif in_relevant == False and in_not_relevant == False: # word never appears in either class\n",
    "        none2.append(term)\n",
    "    \n",
    "    elif in_relevant == False and in_not_relevant == True: # word appears in non relevant papers at least once but never in relevant papers\n",
    "        NR_not_R2.append(term)\n",
    "        \n",
    "    else:                    # word appears in relevant papers at least once but never in non relevant papers\n",
    "        R_not_NR2.append(term)   \n",
    "    \n",
    "    print(\"processed {}/{} terms\".format(ctr, len(query_terms2)))\n",
    "    ctr+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/words_in_neither.pkl', 'wb') as handle:\n",
    "    pickle.dump(none2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data/words_in_both.pkl', 'wb') as handle:\n",
    "    pickle.dump(both2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in both: 22\n",
      "mechan deform\n",
      "hypoton swell\n",
      "mechan transduc\n",
      "mechan stimul\n",
      "mechan load\n",
      "adenosine triphosphate\n",
      "membran stress\n",
      "membran stretch\n",
      "hydrostat pressur\n",
      "hypoton stimul\n",
      "mechan stretch\n",
      "mechan pressur\n",
      "mechan stress\n",
      "mechan forc\n",
      "hypoton exposur\n",
      "hypoton stretch\n",
      "mechan perturb\n",
      "atp\n",
      "hypoton stress\n",
      "hypoton shock\n",
      "mechan strain\n",
      "osmotic stress\n",
      "\n",
      "\n",
      "words in neither: 146\n",
      "\n",
      "hydrostat shock\n",
      "membran shrink\n",
      "osmotic shrink\n",
      "centrifug stretch\n",
      "hyperto agit\n",
      "centrifug exposur\n",
      "hyperto shock\n",
      "hydrostat load\n",
      "fluid swell\n",
      "membran vibrat\n",
      "hydrostat stimul\n",
      "gravit decompress\n",
      "hyperto transduc\n",
      "fluid decompress\n",
      "mechan shrink\n",
      "hyperto exposur\n",
      "centrifug transduc\n",
      "osmotic decompress\n",
      "hydrostat decompress\n",
      "centrifug load\n",
      "gravit shrunk\n",
      "hydrostat agit\n",
      "fluid shrunk\n",
      "hydrostat shrink\n",
      "gravit press\n",
      "hyperto stress\n",
      "centrifug expose\n",
      "osmotic strain\n",
      "hyperto decompress\n",
      "gravit perturb\n",
      "gravit pressur\n",
      "gravit shrink\n",
      "hyperto stimul\n",
      "mechan shrunk\n",
      "hyperto perturb\n",
      "fluid agit\n",
      "hypoton vibrat\n",
      "hyperto forc\n",
      "centrifug deform\n",
      "gravit swell\n",
      "osmotic swell\n",
      "hyperto compress\n",
      "centrifug swell\n",
      "membran transduc\n",
      "centrifug displac\n",
      "centrifug shrunk\n",
      "hypoton shrink\n",
      "fluid strain\n",
      "membran load\n",
      "fluid compress\n",
      "gravit strain\n",
      "gravit compress\n",
      "hydrostat press\n",
      "hypoton strain\n",
      "osmotic transduc\n",
      "hydrostat transduc\n",
      "hyperto vibrat\n",
      "fluid shrink\n",
      "membran expose\n",
      "membran decompress\n",
      "fluid perturb\n",
      "centrifug vibrat\n",
      "hypoton displac\n",
      "hypoton decompress\n",
      "hypoton agit\n",
      "osmotic compress\n",
      "hydrostat swell\n",
      "fluid deform\n",
      "hypoton forc\n",
      "hyperto pressur\n",
      "fluid shock\n",
      "centrifug press\n",
      "hydrostat exposur\n",
      "hydrostat vibrat\n",
      "centrifug perturb\n",
      "hyperto shrink\n",
      "hydrostat displac\n",
      "gravit stretch\n",
      "fluid transduc\n",
      "hydrostat stretch\n",
      "hyperto strain\n",
      "osmotic deform\n",
      "hydrostat shrunk\n",
      "hyperto stretch\n",
      "centrifug compress\n",
      "fluid press\n",
      "membran press\n",
      "fluid expose\n",
      "membran agit\n",
      "hyperto load\n",
      "osmotic agit\n",
      "hyperto shrunk\n",
      "centrifug agit\n",
      "hydrostat expose\n",
      "osmotic load\n",
      "hydrostat strain\n",
      "hypoton transduc\n",
      "centrifug shrink\n",
      "osmotic exposur\n",
      "gravit displac\n",
      "gravit expose\n",
      "centrifug decompress\n",
      "hypoton perturb\n",
      "gravit shock\n",
      "osmotic perturb\n",
      "hyperto press\n",
      "membran shrunk\n",
      "hydrostat stress\n",
      "mechan decompress\n",
      "gravit transduc\n",
      "fluid exposur\n",
      "osmotic displac\n",
      "osmotic vibrat\n",
      "hypoton load\n",
      "osmotic shrunk\n",
      "hyperto deform\n",
      "gravit vibrat\n",
      "hydrostat compress\n",
      "hyperto swell\n",
      "fluid vibrat\n",
      "gravit deform\n",
      "centrifug shock\n",
      "centrifug strain\n",
      "membran compress\n",
      "fluid stretch\n",
      "osmotic expose\n",
      "hyperto displac\n",
      "osmotic forc\n",
      "osmotic stretch\n",
      "hypoton press\n",
      "osmotic pressur\n",
      "hyperto expose\n",
      "hypoton pressur\n",
      "centrifug pressur\n",
      "hypoton shrunk\n",
      "mechan expose\n",
      "gravit agit\n",
      "fluid stress\n",
      "gravit exposur\n",
      "mechan swell\n",
      "hypoton compress\n",
      "hydrostat deform\n",
      "osmotic stimul\n",
      "osmotic press\n",
      "hypoton expose\n",
      "hydrostat perturb\n",
      "\n",
      "\n",
      "words in relevant papers but not irrelevant: 0\n",
      "\n",
      "\n",
      "\n",
      "words in irrelevant paper but not relevant: 32\n",
      "\n",
      "fluid pressur\n",
      "membran forc\n",
      "centrifug stress\n",
      "fluid load\n",
      "fluid stimul\n",
      "mechan shock\n",
      "mechan displac\n",
      "membran displac\n",
      "gravit forc\n",
      "mechan compress\n",
      "mechan exposur\n",
      "membran stimul\n",
      "centrifug stimul\n",
      "membran swell\n",
      "membran shock\n",
      "mechan vibrat\n",
      "fluid forc\n",
      "gravit stress\n",
      "osmotic shock\n",
      "hydrostat forc\n",
      "fluid displac\n",
      "gravit load\n",
      "membran perturb\n",
      "mechan press\n",
      "mechan agit\n",
      "membran pressur\n",
      "gravit stimul\n",
      "membran deform\n",
      "membran strain\n",
      "centrifug forc\n",
      "membran exposur\n",
      "hypoton deform\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "print(\"words in both: {}\".format(len(both1)))\n",
    "for word in both1:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in neither: {}\\n\".format(len(none1)))\n",
    "for word in none1:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in relevant papers but not irrelevant: {}\\n\".format(len(R_not_NR1)))\n",
    "for word in R_not_NR1:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in irrelevant paper but not relevant: {}\\n\".format(len(NR_not_R1)))\n",
    "for word in NR_not_R1:\n",
    "    print(word)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in both: 44\n",
      "mechan deform\n",
      "hypoton swell\n",
      "shock\n",
      "mechan transduc\n",
      "stretch\n",
      "swell\n",
      "mechan\n",
      "hydrostat\n",
      "mechan stimul\n",
      "strain\n",
      "mechan load\n",
      "transduc\n",
      "forc\n",
      "adenosine triphosphate\n",
      "perturb\n",
      "membran stress\n",
      "membran stretch\n",
      "load\n",
      "pressur\n",
      "shrink\n",
      "hydrostat pressur\n",
      "hypoton stimul\n",
      "exposur\n",
      "mechan stretch\n",
      "vibrat\n",
      "displac\n",
      "mechan pressur\n",
      "deform\n",
      "mechan stress\n",
      "mechan forc\n",
      "centrifug\n",
      "stress\n",
      "hypoton exposur\n",
      "hypoton stretch\n",
      "mechan perturb\n",
      "hypoton\n",
      "membran\n",
      "atp\n",
      "hypoton stress\n",
      "compress\n",
      "hypoton shock\n",
      "stimul\n",
      "mechan strain\n",
      "osmotic stress\n",
      "\n",
      "\n",
      "words in neither: 148\n",
      "\n",
      "hydrostat shock\n",
      "membran shrink\n",
      "osmotic shrink\n",
      "centrifug stretch\n",
      "hyperto agit\n",
      "centrifug exposur\n",
      "hyperto shock\n",
      "hydrostat load\n",
      "fluid swell\n",
      "membran vibrat\n",
      "gravit decompress\n",
      "hydrostat stimul\n",
      "hyperto transduc\n",
      "fluid decompress\n",
      "mechan shrink\n",
      "hyperto exposur\n",
      "centrifug transduc\n",
      "osmotic decompress\n",
      "hydrostat decompress\n",
      "centrifug load\n",
      "gravit shrunk\n",
      "hydrostat agit\n",
      "fluid shrunk\n",
      "hydrostat shrink\n",
      "gravit press\n",
      "hyperto stress\n",
      "centrifug expose\n",
      "osmotic strain\n",
      "hyperto decompress\n",
      "gravit perturb\n",
      "gravit pressur\n",
      "gravit shrink\n",
      "hyperto stimul\n",
      "mechan shrunk\n",
      "hyperto perturb\n",
      "fluid agit\n",
      "hypoton vibrat\n",
      "hyperto forc\n",
      "centrifug deform\n",
      "gravit swell\n",
      "osmotic swell\n",
      "hyperto compress\n",
      "centrifug swell\n",
      "membran transduc\n",
      "centrifug displac\n",
      "centrifug shrunk\n",
      "membran load\n",
      "hypoton shrink\n",
      "fluid strain\n",
      "fluid compress\n",
      "gravit strain\n",
      "gravit compress\n",
      "hydrostat press\n",
      "hypoton strain\n",
      "osmotic transduc\n",
      "hydrostat transduc\n",
      "hyperto vibrat\n",
      "fluid shrink\n",
      "membran expose\n",
      "membran decompress\n",
      "fluid perturb\n",
      "centrifug vibrat\n",
      "hypoton displac\n",
      "hypoton decompress\n",
      "hypoton agit\n",
      "osmotic compress\n",
      "hydrostat swell\n",
      "fluid deform\n",
      "hypoton forc\n",
      "hyperto pressur\n",
      "fluid shock\n",
      "centrifug press\n",
      "hydrostat exposur\n",
      "hydrostat vibrat\n",
      "centrifug perturb\n",
      "hydrostat displac\n",
      "gravit stretch\n",
      "fluid transduc\n",
      "hydrostat perturb\n",
      "hydrostat stretch\n",
      "hyperto strain\n",
      "osmotic deform\n",
      "hydrostat shrunk\n",
      "hyperto stretch\n",
      "centrifug compress\n",
      "fluid press\n",
      "membran press\n",
      "fluid expose\n",
      "membran agit\n",
      "hyperto load\n",
      "osmotic agit\n",
      "hyperto shrunk\n",
      "centrifug agit\n",
      "hydrostat expose\n",
      "expose\n",
      "osmotic load\n",
      "hydrostat strain\n",
      "hypoton transduc\n",
      "centrifug shrink\n",
      "osmotic exposur\n",
      "gravit displac\n",
      "gravit expose\n",
      "centrifug decompress\n",
      "hypoton perturb\n",
      "gravit shock\n",
      "osmotic perturb\n",
      "hyperto press\n",
      "membran shrunk\n",
      "hydrostat stress\n",
      "mechan decompress\n",
      "gravit transduc\n",
      "fluid exposur\n",
      "osmotic displac\n",
      "osmotic vibrat\n",
      "hypoton load\n",
      "hyperto\n",
      "osmotic shrunk\n",
      "hyperto deform\n",
      "gravit vibrat\n",
      "hydrostat compress\n",
      "hyperto swell\n",
      "fluid vibrat\n",
      "gravit deform\n",
      "centrifug shock\n",
      "centrifug strain\n",
      "membran compress\n",
      "fluid stretch\n",
      "osmotic expose\n",
      "hyperto displac\n",
      "osmotic forc\n",
      "osmotic stretch\n",
      "hypoton press\n",
      "osmotic pressur\n",
      "hyperto expose\n",
      "hypoton pressur\n",
      "centrifug pressur\n",
      "hypoton shrunk\n",
      "mechan expose\n",
      "gravit agit\n",
      "fluid stress\n",
      "gravit exposur\n",
      "mechan swell\n",
      "hypoton compress\n",
      "hydrostat deform\n",
      "osmotic stimul\n",
      "osmotic press\n",
      "hypoton expose\n",
      "hyperto shrink\n",
      "\n",
      "\n",
      "words in relevant papers but not irrelevant: 0\n",
      "\n",
      "\n",
      "\n",
      "words in irrelevant paper but not relevant: 38\n",
      "\n",
      "fluid pressur\n",
      "membran forc\n",
      "centrifug stress\n",
      "osmotic\n",
      "fluid load\n",
      "fluid stimul\n",
      "mechan shock\n",
      "shrunk\n",
      "mechan displac\n",
      "membran displac\n",
      "gravit forc\n",
      "press\n",
      "mechan compress\n",
      "mechan exposur\n",
      "membran stimul\n",
      "centrifug stimul\n",
      "membran swell\n",
      "membran shock\n",
      "mechan vibrat\n",
      "gravit stress\n",
      "fluid forc\n",
      "decompress\n",
      "gravit\n",
      "osmotic shock\n",
      "hydrostat forc\n",
      "fluid displac\n",
      "gravit load\n",
      "membran perturb\n",
      "mechan press\n",
      "agit\n",
      "mechan agit\n",
      "membran pressur\n",
      "gravit stimul\n",
      "membran deform\n",
      "membran strain\n",
      "centrifug forc\n",
      "membran exposur\n",
      "hypoton deform\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "print(\"words in both: {}\".format(len(both2)))\n",
    "for word in both2:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in neither: {}\\n\".format(len(none2)))\n",
    "for word in none2:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in relevant papers but not irrelevant: {}\\n\".format(len(R_not_NR2)))\n",
    "for word in R_not_NR2:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "\n",
    "print(\"words in irrelevant paper but not relevant: {}\\n\".format(len(NR_not_R2)))\n",
    "for word in NR_not_R2:\n",
    "    print(word)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting words that appear in most papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if papers had neither atp not adenosine triphosphate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_atp       = 0\n",
    "no_adenosine = 0\n",
    "neither      = 0\n",
    "neither_R    = 0\n",
    "neither_NR   = 0\n",
    "\n",
    "for index, row in text_df.iterrows():\n",
    "    if 'atp' not in row.all_text_corpus:\n",
    "        no_atp+=1\n",
    "        \n",
    "    if 'adenosine triphosphate' not in row.all_text_corpus:\n",
    "        no_adenosine+=1\n",
    "\n",
    "    if 'adenosine triphosphate' not in row.all_text_corpus and 'atp' not in row.all_text_corpus:\n",
    "        neither +=1\n",
    "        \n",
    "        if row.relevant == True:\n",
    "            neither_R +=1\n",
    "        else:\n",
    "            neither_NR +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of irrelevant papers that don't mention ATP: 1307\n",
      "number of relevant papers that don't mention ATP:   0\n"
     ]
    }
   ],
   "source": [
    "print(\"number of irrelevant papers that don't mention ATP: {}\".format(neither_NR))\n",
    "print(\"number of relevant papers that don't mention ATP:   {}\".format(neither_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of irrelevant papers that don't mention any query term: 1045\n",
      "number of relevant papers that don't mention any query term: 0\n"
     ]
    }
   ],
   "source": [
    "no_qt_tally1 = 0\n",
    "no_qt_tally_R1 = 0\n",
    "no_qt_tally_NR1 = 0\n",
    "\n",
    "updated_df1 = []\n",
    "for index, row in text_df.iterrows():\n",
    "    has_qt = False\n",
    "    \n",
    "    for word in query_terms1:\n",
    "        \n",
    "        if word in row.all_text_corpus:\n",
    "            has_qt=True\n",
    "\n",
    "    if not has_qt: # if none of the query terms were present\n",
    "        no_qt_tally1+=1\n",
    "        if row.relevant==True:\n",
    "            no_qt_tally_R1 +=1\n",
    "        else:\n",
    "            no_qt_tally_NR1 +=1\n",
    "    else:\n",
    "        updated_df1.append(row)\n",
    "        \n",
    "print(\"number of irrelevant papers that don't mention any query term: {}\".format(no_qt_tally_NR1))\n",
    "print(\"number of relevant papers that don't mention any query term: {}\".format(no_qt_tally_R1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of irrelevant papers that don't mention any query term: 244\n",
      "number of relevant papers that don't mention any query term: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "no_qt_tally2 = 0\n",
    "no_qt_tally_R2 = 0\n",
    "no_qt_tally_NR2 = 0\n",
    "\n",
    "updated_df2 = []\n",
    "for index, row in text_df.iterrows():\n",
    "    has_qt = False\n",
    "    \n",
    "    for word in query_terms2:\n",
    "        \n",
    "        if word in row.all_text_corpus:\n",
    "            has_qt=True\n",
    "\n",
    "    if not has_qt: # if none of the query terms were present\n",
    "        no_qt_tally2+=1\n",
    "        if row.relevant==True:\n",
    "            no_qt_tally_R2 +=1\n",
    "        else:\n",
    "            no_qt_tally_NR2 +=1\n",
    "    else:\n",
    "        updated_df2.append(row)\n",
    "        \n",
    "print(\"number of irrelevant papers that don't mention any query term: {}\".format(no_qt_tally_NR2))\n",
    "print(\"number of relevant papers that don't mention any query term: {}\".format(no_qt_tally_R2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(data = updated_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = []\n",
    "ctr = 0\n",
    "for index, row in text_df.iterrows():\n",
    "\n",
    "\n",
    "    if 'adenosine triphosphate' in row.all_text_corpus or 'atp' in row.all_text_corpus:\n",
    "        updated_df.append(row)\n",
    "    else:\n",
    "        ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(data = updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qt_count, qt_count_R, qt_count_NR = num_paper_per_keyword(query_terms, text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevent, irrelevant = get_num_relevant(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant: True\n",
      "irrelevant: 6878\n"
     ]
    }
   ],
   "source": [
    "print(\"relevant: {}\".format(relevant))\n",
    "print(\"irrelevant: {}\".format(irrelevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qt_count_R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-b0b153fa71f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqt_count_R_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelevant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqt_count_R\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mqt_count_NR_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mirrelevant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqt_count_NR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qt_count_R' is not defined"
     ]
    }
   ],
   "source": [
    "qt_count_R_normalized = normalize(relevant, qt_count_R)\n",
    "qt_count_NR_normalized = normalize(irrelevant, qt_count_NR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qt_count_R_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qt_count_NR_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_from_dict(dictionary, n):\n",
    "    ctr = 0\n",
    "    new_dict = {}\n",
    "    for key in dictionary.keys():\n",
    "        if ctr<n:\n",
    "            new_dict[key] = dictionary[key]\n",
    "        ctr +=1\n",
    "    return new_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphs and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atp is in 274 relevant papers\n",
      "adenosine triphosphate is in 242 relevant papers\n",
      "atp and adenosine triphosphate are in 239 relevant papers\n",
      "atp but no adenosine triphosphate is in 35 relevant papers\n",
      "adenosine triphosphate but no atp is in 3 relevant papers\n",
      "neither atp nor adenosine triphosphate is in 0 relevant papers\n"
     ]
    }
   ],
   "source": [
    "atp = 0\n",
    "adenosine = 0\n",
    "both = 0\n",
    "adenosine_no_atp = 0\n",
    "atp_no_adenosine = 0\n",
    "neither = 0\n",
    "\n",
    "for row in text_df.loc[text_df['relevant'] == True].iterrows():\n",
    "    row = row[1]\n",
    "    if 'atp' in row.all_text_corpus and 'adenosine triphosphate' in row.all_text_corpus:\n",
    "\n",
    "        both+=1\n",
    "    elif 'atp' in row.all_text_corpus and 'adenosine triphosphate' not in row.all_text_corpus:\n",
    "        atp_no_adenosine +=1\n",
    "    \n",
    "    elif 'atp' not in row.all_text_corpus and 'adenosine triphosphate' in row.all_text_corpus:\n",
    "        adenosine_no_atp +=1\n",
    "        \n",
    "       \n",
    "    else:\n",
    "        neither+=1\n",
    "        \n",
    "    if 'atp' in row.all_text_corpus:\n",
    "        atp+=1\n",
    "    \n",
    "    if 'adenosine triphosphate' in row.all_text_corpus:\n",
    "        adenosine+=1\n",
    "    \n",
    "\n",
    "            \n",
    "print(\"atp is in {} relevant papers\".format(atp))  \n",
    "print(\"adenosine triphosphate is in {} relevant papers\".format(adenosine))\n",
    "print(\"atp and adenosine triphosphate are in {} relevant papers\".format(both))\n",
    "print(\"atp but no adenosine triphosphate is in {} relevant papers\".format(atp_no_adenosine))\n",
    "print(\"adenosine triphosphate but no atp is in {} relevant papers\".format(adenosine_no_atp))\n",
    "print(\"neither atp nor adenosine triphosphate is in {} relevant papers\".format(neither))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_terms1 = [] # list of the original query terms that show up in the text\n",
    "for word in query_terms1:\n",
    "    if word not in none1:\n",
    "        used_terms1.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_terms2 = [] # list of the original query terms that show up in the text\n",
    "for word in query_terms2:\n",
    "    if word not in none2:\n",
    "        used_terms2.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/used_query_terms.pkl', 'wb') as f:\n",
    "    pickle.dump(used_terms2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechan_words1 = [word for word in used_terms1 if word != 'atp' and word != 'adenosine triphosphate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechan_words2 = [word for word in used_terms2 if word != 'atp' and word != 'adenosine triphosphate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_qt_tally1 = 0\n",
    "no_qt_tally_R1 = 0\n",
    "no_qt_tally_NR1 = 0\n",
    "no_qt_R1 = []\n",
    "\n",
    "updated_df = []\n",
    "for index, row in text_df.iterrows():\n",
    "    has_qt = False\n",
    "    \n",
    "    for word in mechan_words1:\n",
    "        \n",
    "        if word in row.all_text_corpus:\n",
    "            has_qt=True\n",
    "\n",
    "    if not has_qt: # if none of the query terms were present\n",
    "        no_qt_tally1+=1\n",
    "        if row.relevant==True:\n",
    "            no_qt_tally_R1 +=1\n",
    "            no_qt_R1.append(row) \n",
    "        else:\n",
    "            no_qt_tally_NR1 +=1\n",
    "    else:\n",
    "        updated_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of papers with none of the mechanical terms: 5578\n",
      "number of irrelevant papers with none of the mechanical terms: 5453\n",
      "number of relevant papers with none of the mechanical terms: 125\n"
     ]
    }
   ],
   "source": [
    "print(\"number of papers with none of the mechanical terms: {}\".format(no_qt_tally1))\n",
    "print(\"number of irrelevant papers with none of the mechanical terms: {}\".format(no_qt_tally_NR1))\n",
    "print(\"number of relevant papers with none of the mechanical terms: {}\".format(no_qt_tally_R1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_qt_tally2 = 0\n",
    "no_qt_tally_R2 = 0\n",
    "no_qt_tally_NR2 = 0\n",
    "no_qt_R2 = []\n",
    "\n",
    "updated_df = []\n",
    "for index, row in text_df.iterrows():\n",
    "    has_qt = False\n",
    "    \n",
    "    for word in mechan_words2:\n",
    "        \n",
    "        if word in row.all_text_corpus:\n",
    "            has_qt=True\n",
    "\n",
    "    if not has_qt: # if none of the query terms were present\n",
    "        no_qt_tally2+=1\n",
    "        if row.relevant==True:\n",
    "            no_qt_tally_R2 +=1\n",
    "            no_qt_R2.append(row) \n",
    "        else:\n",
    "            no_qt_tally_NR2 +=1\n",
    "    else:\n",
    "        updated_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of papers with none of the mechanical terms: 1074\n",
      "number of irrelevant papers with none of the mechanical terms: 1065\n",
      "number of relevant papers with none of the mechanical terms: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"number of papers with none of the mechanical terms: {}\".format(no_qt_tally2))\n",
    "print(\"number of irrelevant papers with none of the mechanical terms: {}\".format(no_qt_tally_NR2))\n",
    "print(\"number of relevant papers with none of the mechanical terms: {}\".format(no_qt_tally_R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for this study we've been able to remove 2000 irrelevant and only 9 relevant papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have shown previously that wounding of human corneal epithelial (HCE) cells resulted in epidermal growth factor receptor (EGFR) transactivation through ectodomain shedding of heparin-binding EGF-like growth factor (HB-EGF). However, the initial signal to trigger these signaling events in response to cell injury remains elusive. In the present study, we investigated the role of ATP released from the injured cells in EGFR transactivation in HCE cells as well as in BEAS 2B cells, a bronchial epithelial cell line. Wounding of epithelial monolayer resulted in the release of ATP into the culture medium. The wound-induced rapid activation of phosphatidylinositol-3-kinase (PI3K) and extracellular signal-regulated kinase (ERK) pathways in HCE cells was attenuated by eliminating extracellular ATP, ADP and adenosine. The nonhydrolyzable ATP analog ATP-gamma-S induced rapid and sustained EGFR activation that depended on HB-EGF shedding and ADAM (a disintegrin and metalloproteinase). Targeting pathways leading to HB-EGF shedding and EGFR activation attenuated ATP-gamma-S-enhanced closure of small scratch wounds. The purinoceptor antagonist reactive blue 2 decreased wound closure and attenuated ATP-gamma-S induced HB-EGF shedding. Taken together, our data suggest that ATP, released upon epithelial injury, acts as an early signal to trigger cell responses including an increase in HB-EGF shedding, subsequent EGFR transactivation and its downstream signaling, resulting in wound healing.\n",
      "\n",
      "\n",
      "BACKGROUND: Rotational atherectomy with the Rotablator catheter has improved percutaneous treatment of certain coronary atherosclerotic lesions, but the \"no-reflow\" phenomenon remains a serious complication. Because platelet activation by rotablation may contribute to the no-reflow phenomenon, we developed an in vitro system to test the effect of rotablation on platelets in the absence or presence of platelet GP IIb/IIIa receptor blockade with abciximab.\r",
      "METHODS AND RESULTS: Platelet-rich plasma (PRP) was prepared from 28 healthy human volunteers. PRP was divided into 4 samples: (1) no treatment, (2) 6D1 (anti-GP Ib), (3) c7E3 Fab (anti-GP IIb/IIIa+alpha(v)beta3), and (4) c7E3 Fab+6D1. Samples were pumped through a flow chamber containing a 2.5-mm burr rotating at various speeds and then placed in an aggregometer. PRP samples tested in the absence of antibody underwent more rapid and extensive aggregation when rotablated at 150000 and 180000 rpm compared with 0 rpm (P<0.001 at both speeds). Preincubation of platelets with c7E3 Fab decreased the slope of aggregation at each rotablation speed, with 98%, 79%, and 71% reductions at 70000, 150000, and 180000 rpm, respectively (P=0.09 for 70000 and P<0.001 for both 150000 and 180000 rpm). Preincubation of platelets with 6D1 did not decrease the slope of aggregation at any rotablation speed (P>0.5, P=0.99, and P=0.091 for 70000, 150000, and 180000 rpm). Platelet ATP release, a marker of granule release and cell damage, was markedly increased at 180000 rpm (P=0.002 compared with 0 rpm in the control group). Electron microscopy revealed extensive rotablation-induced platelet damage at 150000 and 180000 rpm, and leakage of LDH confirmed platelet lysis at these speeds (P=0.002 and P<0.001 compared with 0 rpm).\r",
      "CONCLUSIONS: High-speed rotablation induces platelet activation of PRP, leading to aggregation; pretreating PRP with abciximab decreases the aggregation. These data suggest that pretreatment of patients with abciximab may decrease rotablation-induced platelet aggregation during rotational atherectomy.\n",
      "\n",
      "\n",
      "Prior studies have demonstrated P2X receptor expression in the majority of nodose neurons. Immunoreactivity for P2X receptors has also been seen in putative gastric mechanoreceptors, the intraganglionic laminar endings. We therefore hypothesized that deletion of P2X3 receptors will blunt responses to gastric distension in vagal sensory neurons. Using wildtype and P2X3 <sup>-/-</sup> mice, we examined responses to purinergic agonists in retrogradely labelled gastric sensory neurons with patch-clamp techniques. Activation of gastro-oesophageal neurons by fluid distension was studied with intracellular electrodes. Distension-evoked ATP release into the gastric lumen was determined with the luciferase assay and intake and gastric emptying of a solid meal was assessed. ATP triggered inward currents in 80% of gastric nodose neurons. In P2X3<sup>-/-</sup> mice, the peak current density was lower compared to controls. Ten of 14 controls but none of 30 neurons from P2X3<sup>-/-</sup> mice responded to alpha,beta-metATP. Gastro-oesophageal sensory neurons of P2X3<sup>-/-</sup> mice showed a blunted response to fluid distension of oesophagus and stomach. This difference was not explained by differences in distension-evoked ATP release, which did not differ between knockout mice and controls. Food intake during a 3-h period was lower in P2X3<sup>-/-</sup> mice. Gastric emptying of a solid meal was slightly faster in knockout mice after 1.5 h, but did not differ between groups at 3 h. Our data support a role of purinergic signalling in gastric vagal afferents. Considering the role of vagal input in sensations of fullness or nausea, P2X receptors may be interesting treatment targets for dyspeptic symptoms.  2009 Blackwell Publishing Ltd.\n",
      "\n",
      "\n",
      "1. HL60 promyeloid cells contain high intracellular concentrations of inositol polyphosphates, notably inositol 1,3,4,5,6-pentakisphosphate (InsP5) and inositol hexakisphosphate (InsP6). To determine their intracellular location(s), we studied the release of inositol (poly)phosphates, of ATP, and of cytosolic and granule-enclosed enzymes from cells permeabilized by four different methods. 2. When cells were treated with digitonin, all of the inositol phosphates were released in parallel with the cytosolic constituents. Most of the InsP5 and InsP6 was released before significant permeabilization of azurophil granules. 3. Similar results were obtained from cells preloaded with ethylene glycol and permeabilized by osmotic lysis. 4. Electroporation at approximately 500 V/cm caused rapid release of free inositol. Higher field strengths provoked release of most of the ATP, InsP5 and InsP6, but only slight release of the intracellular enzymes. Multiple discharges released approximately 80-90% of total InsP5 and InsP6. In the absence of bivalent-cation chelators, InsP5 and InsP6 were released less readily than ATP. 5. Treatment of cells with Staphylococcus aureus alpha-toxin caused quantitative release of inositol and ATP, without release of intracellular enzymes. However, inositol phosphates were released much less readily than inositol or ATP. Even after prolonged incubation with a high concentration of alpha-toxin, only approximately 50-70% of InsP2, InsP3 and InsP4 and < or = 20% of InsP5 and InsP6 were released, indicating that the high charge or large hydrated radius of InsP5 and InsP6 might limit their release through small toxin-induced pores. 6. These results indicate that most intracellular inositol metabolites are either in, or in rapid exchange with, the cytosolic compartment of HL60 cells. However, they leave open the possibility that a small proportion of cellular InsP5 and InsP6 (< or = 10-20%) might be in some intracellular bound form.\n",
      "\n",
      "\n",
      "Objective: To investigate local vascular control in the isolated perfused premenopausal human ovary by measuring flow-induced release of vasoactive substances. Design: Release of adenosine 5' triphosphate (ATP), substance P (SP), endothelin (ET), and vasopressin (AVP) from the ovarian vascular endothelium was estimated in perfusate under basal conditions and during two periods of increased flow. Main outcome measures: Vascular resistance; ATP, SP, ET and AVP release. Results: The mean ratio (pressure/flow during increased flow):(pressure/flow at basal flow) was 1.27 +/- 0.04 for the first, and 1.15 +/- 0.05 for the second period of increased flow (n = 10), indicating significant vasoconstriction (P < 0.01 and 0.05, respectively), present to a greater extent during the first period of increased flow compared to the second (P < 0.05). ATP release was seen in response to increased flow (n = 8, P < 0.05). From 12 ovarian bed preparations, five released ET and SP and three of these released AVP. Four of the five perfused ovaries that released peptides contained either a developing follicle or a corpus luteum while all those that showed no peptide release were inactive. Conclusions: ATP release may play a role in the local control of the human premenopausal ovarian vasculature independent of ovulatory status. Peptides may also contribute to local vascular control in the ovary and their release from predominantly active ovaries suggests a relationship between ovulation and vascular endothelial function.\n",
      "\n",
      "\n",
      "Low-intensity pulsed ultrasound (LIPUS) is commonly used in the treatment of fractures and nonunion-promoting acceleration of healing fractures. In this report, we investigated the implication of the P2 receptors in osteoblast proliferation induced with LIPUS treatment. We observed that ADP, ATP, UTP, and UDP promote osteoblast increase and an increase of intracellular Ca(2+), through activation of P2Y receptors. Osteoblasts' expression of the P2Y(1), P2Y(2), P2Y(4), P2Y(6), P2Y(11), P2Y(12), and P2Y(13) receptors was confirmed. In addition, the participation of the P2Y(1) receptor in osteoblast increase and the ADP-dependent increase of Ca(2+) concentration were shown. Furthermore, release of ATP/purines was induced by LIPUS treatment. Finally, LIPUS-dependent osteoblast increase was abolished in the presence of the Ca(2+) chelator (BAPTA), the inositol 1,4,5-trisphosphate receptor antagonist (2-APB), and the selective P2Y(1) receptor antagonist (MRS2179). In conclusion, LIPUS treatment induces osteoblastogenesis via the release of purines, such as ATP, activating P2Y receptors, mainly the P2Y(1) receptor.Copyright (c) 2009 Elsevier Inc. All rights reserved.\n",
      "\n",
      "\n",
      "A novel microflow technique is used to demonstrate that a weakened oxidant defense system found in diabetic erythrocytes leads to decreased levels of deformation-induced release of adenosine triphosphate (ATP) from erythrocytes. Addition of an oxidant to rabbit erythrocytes resulted in a 63% decrease in deformation-induced ATP release before eventually recovering to a value that was statistically equivalent to the initial value. Inhibition of glucose-6-phosphate dehydrogenase prevents recovery from the oxidant attack. Finally, results indicated that the ATP release from the erythrocytes of type II diabetics (91 nM +/- 10 nM) was less than half of that measured from the erythrocytes of healthy controls (190 +/- 10 nM). These data suggest that the antioxidant status of erythrocytes is a critical determinant in the ability of these cells to release ATP, a known nitric oxide stimulus.\n",
      "\n",
      "\n",
      "Extracellular ATP and other nucleotides are important autocrine/paracrine mediators that regulate diverse processes critical for lung function, including mucociliary clearance, surfactant secretion, and local blood flow. Cellular ATP release is mechanosensitive; however, the impact of physical stimuli on ATP release during breathing has never been tested in intact lungs in real time and remains elusive. In this pilot study, we investigated inflation-induced ATP release in rat lungs ex vivo by real-time luciferin-luciferase (LL) bioluminescence imaging coupled with simultaneous infrared tissue imaging to identify ATP-releasing sites. With LL solution introduced into air spaces, brief inflation of such edematous lung (1 s, ~20 cmH2O) induced transient (<30 s) ATP release in a limited number of air-inflated alveolar sacs during their recruitment/opening. Released ATP reached concentrations of ~10(-6) M, relevant for autocrine/paracrine signaling, but it remained spatially restricted to single alveolar sacs or their clusters. ATP release was stimulus dependent: prolonged (100 s) inflation evoked long-lasting ATP release that terminated upon alveoli deflation/derecruitment while cyclic inflation/suction produced cyclic ATP release. With LL introduced into blood vessels, inflation induced transient ATP release in many small patchlike areas the size of alveolar sacs. Findings suggest that inflation induces ATP release in both alveoli and the surrounding blood capillary network; the functional units of ATP release presumably consist of alveolar sacs or their clusters. Our study demonstrates the feasibility of real-time ATP release imaging in ex vivo lungs and provides the first direct evidence of inflation-induced ATP release in lung air spaces and in pulmonary blood capillaries, highlighting the importance of purinergic signaling in lung function.Copyright  2016 the American Physiological Society.\n",
      "\n",
      "\n",
      "Extracellular ATP and other purines are ubiquitous mediators of local intercellular signaling within the body. While the last two decades have witnessed enormous progress in uncovering and characterizing purinergic receptors and extracellular enzymes controlling purinergic signals, our understanding of the initiating step in this cascade, i.e., ATP release, is still obscure. Imaging of extracellular ATP by luciferin-luciferase bioluminescence offers the advantage of studying ATP release and distribution dynamics in real time. However, low-light signal generated by bioluminescence reactions remains the major obstacle to imaging such rapid processes, imposing substantial constraints on its spatial and temporal resolution. We have developed an improved microscopy system for real-time ATP imaging, which detects ATP-dependent luciferin-luciferase luminescence at ~10 frames/s, sufficient to follow rapid ATP release with sensitivity of ~10 nM and dynamic range up to 100 muM. In addition, simultaneous differential interference contrast cell images are acquired with infra-red optics. Our imaging method: (1) identifies ATP-releasing cells or sites, (2) determines absolute ATP concentration and its spreading manner at release sites, and (3) permits analysis of ATP release kinetics from single cells. We provide instrumental details of our approach and give several examples of ATP-release imaging at cellular and tissue levels, to illustrate its potential utility.Copyright  2013 Elsevier Inc. All rights reserved.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at the papers that don't mention any of the mechanical words\n",
    "for row in no_qt_R2:\n",
    "    for word in mechan_words2:\n",
    "        \n",
    "        if word in row.all_text_corpus:\n",
    "            print(\"{} found\".format(word))\n",
    "    print(row['original abstract'])\n",
    "    print('\\n')\n",
    " \n",
    "# note try unigram keywords, only keep papers whose keywords appear near sentences with atp (1 or 2 sentence range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "atp_count = []\n",
    "\n",
    "for row in text_df.iterrows():\n",
    "    row = row[1]\n",
    "    atp = 0\n",
    "    atp+=row.all_text.count('atp')\n",
    "    adenosine = 0\n",
    "    adenosine+=row.all_text.count('adenosine triphosphate')\n",
    "    atp_count.append((atp, adenosine, row.relevant))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "atp_count_R  = [tup for tup in atp_count if  tup[-1]==True]\n",
    "atp_count_NR = [tup for tup in atp_count if tup[-1]==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36, 0, True),\n",
       " (23, 1, True),\n",
       " (29, 1, True),\n",
       " (6, 0, True),\n",
       " (39, 1, True),\n",
       " (21, 1, True),\n",
       " (17, 0, True),\n",
       " (24, 1, True),\n",
       " (12, 1, True),\n",
       " (11, 1, True),\n",
       " (33, 1, True),\n",
       " (29, 1, True),\n",
       " (24, 1, True),\n",
       " (12, 1, True),\n",
       " (3, 1, True),\n",
       " (12, 1, True),\n",
       " (20, 1, True),\n",
       " (9, 1, True),\n",
       " (15, 0, True),\n",
       " (23, 1, True),\n",
       " (12, 1, True),\n",
       " (15, 0, True),\n",
       " (18, 1, True),\n",
       " (12, 1, True),\n",
       " (15, 1, True),\n",
       " (31, 1, True),\n",
       " (21, 1, True),\n",
       " (27, 1, True),\n",
       " (30, 1, True),\n",
       " (9, 0, True),\n",
       " (30, 1, True),\n",
       " (21, 1, True),\n",
       " (38, 1, True),\n",
       " (48, 1, True),\n",
       " (15, 1, True),\n",
       " (3, 0, True),\n",
       " (15, 1, True),\n",
       " (45, 1, True),\n",
       " (36, 1, True),\n",
       " (32, 1, True),\n",
       " (12, 0, True),\n",
       " (17, 1, True),\n",
       " (42, 1, True),\n",
       " (21, 1, True),\n",
       " (15, 1, True),\n",
       " (24, 1, True),\n",
       " (12, 1, True),\n",
       " (0, 1, True),\n",
       " (21, 1, True),\n",
       " (33, 1, True),\n",
       " (43, 1, True),\n",
       " (13, 1, True),\n",
       " (0, 1, True),\n",
       " (27, 1, True),\n",
       " (12, 0, True),\n",
       " (30, 1, True),\n",
       " (30, 1, True),\n",
       " (15, 1, True),\n",
       " (27, 1, True),\n",
       " (0, 1, True),\n",
       " (33, 1, True),\n",
       " (14, 1, True),\n",
       " (45, 1, True),\n",
       " (45, 1, True),\n",
       " (39, 1, True),\n",
       " (9, 1, True),\n",
       " (24, 1, True),\n",
       " (14, 2, True),\n",
       " (27, 1, True),\n",
       " (45, 1, True),\n",
       " (21, 1, True),\n",
       " (27, 1, True),\n",
       " (29, 1, True),\n",
       " (26, 1, True),\n",
       " (21, 1, True),\n",
       " (15, 1, True),\n",
       " (36, 1, True),\n",
       " (12, 0, True),\n",
       " (27, 0, True),\n",
       " (27, 1, True),\n",
       " (18, 1, True),\n",
       " (69, 1, True),\n",
       " (9, 1, True),\n",
       " (18, 1, True),\n",
       " (48, 1, True),\n",
       " (30, 1, True),\n",
       " (15, 0, True),\n",
       " (27, 1, True),\n",
       " (64, 1, True),\n",
       " (20, 1, True),\n",
       " (12, 1, True),\n",
       " (27, 1, True),\n",
       " (30, 1, True),\n",
       " (21, 1, True),\n",
       " (6, 1, True),\n",
       " (36, 1, True),\n",
       " (6, 1, True),\n",
       " (9, 1, True),\n",
       " (18, 1, True),\n",
       " (33, 1, True),\n",
       " (25, 1, True),\n",
       " (30, 1, True),\n",
       " (30, 1, True),\n",
       " (24, 0, True),\n",
       " (33, 1, True),\n",
       " (27, 1, True),\n",
       " (6, 0, True),\n",
       " (24, 1, True),\n",
       " (19, 1, True),\n",
       " (21, 1, True),\n",
       " (3, 0, True),\n",
       " (30, 1, True),\n",
       " (6, 1, True),\n",
       " (9, 1, True),\n",
       " (11, 0, True),\n",
       " (39, 1, True),\n",
       " (33, 1, True),\n",
       " (24, 1, True),\n",
       " (26, 1, True),\n",
       " (30, 1, True),\n",
       " (33, 1, True),\n",
       " (11, 1, True),\n",
       " (9, 1, True),\n",
       " (28, 1, True),\n",
       " (48, 0, True),\n",
       " (27, 1, True),\n",
       " (41, 2, True),\n",
       " (6, 1, True),\n",
       " (15, 1, True),\n",
       " (21, 1, True),\n",
       " (21, 1, True),\n",
       " (38, 1, True),\n",
       " (18, 1, True),\n",
       " (44, 1, True),\n",
       " (8, 1, True),\n",
       " (6, 0, True),\n",
       " (42, 1, True),\n",
       " (27, 1, True),\n",
       " (18, 1, True),\n",
       " (24, 1, True),\n",
       " (33, 1, True),\n",
       " (14, 1, True),\n",
       " (9, 1, True),\n",
       " (15, 1, True),\n",
       " (29, 1, True),\n",
       " (15, 0, True),\n",
       " (36, 1, True),\n",
       " (23, 1, True),\n",
       " (42, 1, True),\n",
       " (30, 1, True),\n",
       " (9, 1, True),\n",
       " (6, 1, True),\n",
       " (33, 1, True),\n",
       " (19, 1, True),\n",
       " (9, 1, True),\n",
       " (6, 1, True),\n",
       " (6, 0, True),\n",
       " (12, 1, True),\n",
       " (24, 1, True),\n",
       " (18, 1, True),\n",
       " (29, 1, True),\n",
       " (21, 1, True),\n",
       " (15, 1, True),\n",
       " (12, 0, True),\n",
       " (3, 1, True),\n",
       " (21, 1, True),\n",
       " (32, 1, True),\n",
       " (33, 1, True),\n",
       " (23, 1, True),\n",
       " (9, 1, True),\n",
       " (50, 1, True),\n",
       " (27, 1, True),\n",
       " (6, 1, True),\n",
       " (18, 1, True),\n",
       " (15, 1, True),\n",
       " (54, 1, True),\n",
       " (29, 1, True),\n",
       " (26, 1, True),\n",
       " (44, 1, True),\n",
       " (33, 1, True),\n",
       " (15, 1, True),\n",
       " (9, 1, True),\n",
       " (17, 1, True),\n",
       " (28, 1, True),\n",
       " (15, 1, True),\n",
       " (15, 1, True),\n",
       " (33, 1, True),\n",
       " (12, 0, True),\n",
       " (27, 1, True),\n",
       " (35, 1, True),\n",
       " (18, 1, True),\n",
       " (14, 1, True),\n",
       " (12, 1, True),\n",
       " (6, 1, True),\n",
       " (24, 1, True),\n",
       " (21, 1, True),\n",
       " (21, 1, True),\n",
       " (26, 1, True),\n",
       " (15, 1, True),\n",
       " (23, 1, True),\n",
       " (21, 0, True),\n",
       " (27, 0, True),\n",
       " (36, 1, True),\n",
       " (33, 0, True),\n",
       " (21, 1, True),\n",
       " (9, 1, True),\n",
       " (3, 1, True),\n",
       " (9, 1, True),\n",
       " (25, 1, True),\n",
       " (24, 1, True),\n",
       " (23, 1, True),\n",
       " (27, 1, True),\n",
       " (15, 1, True),\n",
       " (8, 1, True),\n",
       " (3, 1, True),\n",
       " (21, 1, True),\n",
       " (15, 1, True),\n",
       " (18, 1, True),\n",
       " (3, 1, True),\n",
       " (15, 1, True),\n",
       " (45, 1, True),\n",
       " (27, 1, True),\n",
       " (27, 1, True),\n",
       " (30, 1, True),\n",
       " (38, 1, True),\n",
       " (9, 1, True),\n",
       " (26, 1, True),\n",
       " (42, 1, True),\n",
       " (27, 1, True),\n",
       " (17, 1, True),\n",
       " (14, 0, True),\n",
       " (6, 1, True),\n",
       " (6, 1, True),\n",
       " (9, 1, True),\n",
       " (15, 1, True),\n",
       " (27, 0, True),\n",
       " (17, 1, True),\n",
       " (20, 1, True),\n",
       " (9, 1, True),\n",
       " (12, 0, True),\n",
       " (39, 1, True),\n",
       " (30, 0, True),\n",
       " (12, 1, True),\n",
       " (24, 1, True),\n",
       " (12, 1, True),\n",
       " (21, 0, True),\n",
       " (46, 0, True),\n",
       " (48, 0, True),\n",
       " (36, 1, True),\n",
       " (42, 1, True),\n",
       " (18, 1, True),\n",
       " (12, 1, True),\n",
       " (21, 1, True),\n",
       " (3, 1, True),\n",
       " (3, 0, True),\n",
       " (59, 1, True),\n",
       " (12, 0, True),\n",
       " (33, 1, True),\n",
       " (30, 1, True),\n",
       " (30, 1, True),\n",
       " (33, 1, True),\n",
       " (21, 0, True),\n",
       " (27, 1, True),\n",
       " (24, 2, True),\n",
       " (18, 1, True),\n",
       " (29, 1, True),\n",
       " (60, 1, True),\n",
       " (24, 1, True),\n",
       " (33, 1, True),\n",
       " (26, 1, True),\n",
       " (35, 1, True),\n",
       " (27, 1, True),\n",
       " (36, 1, True),\n",
       " (21, 1, True),\n",
       " (45, 1, True),\n",
       " (36, 1, True),\n",
       " (30, 1, True)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atp_count_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_by_atp_count = {}\n",
    "for num in range(20):\n",
    "    \n",
    "    true = 0\n",
    "    false = 0\n",
    "    row_count = 0\n",
    "    for row in atp_count:\n",
    "        \n",
    "        if row[0] == num:\n",
    "            row_count+=1\n",
    "            if row[-1]==True:\n",
    "                true+=1\n",
    "            else:\n",
    "                false+=1\n",
    "    rows_by_atp_count[num] = (true, false)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_by_atp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
